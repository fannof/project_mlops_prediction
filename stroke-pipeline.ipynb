{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278b030f",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c9a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from modules.pipeline import init_local_pipeline\n",
    "from modules.components import init_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c98fa",
   "metadata": {},
   "source": [
    "### SET VARIABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee540d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'stroke-pipeline'\n",
    "\n",
    "DATA_ROOT = 'data'\n",
    "TRANSFORM_MODULE_FILE = 'modules/transform.py'\n",
    "TRAINER_MODULE_FILE = 'modules/trainer.py'\n",
    "\n",
    "OUTPUT_BASE = 'output'\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, 'serving_model')\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, 'metadata.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dea73f",
   "metadata": {},
   "source": [
    "### RUN PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5702b230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230896   nanos: 257527351 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230896   nanos: 291522979 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230896   nanos: 373526096 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230896   nanos: 388529062 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230896   nanos: 334523439 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230896   nanos: 354523420 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230896   nanos: 334523439 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230896   nanos: 353523492 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230912   nanos: 491946935 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_26\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230912   nanos: 499948263 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_28\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230912   nanos: 495949268 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_27\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230912   nanos: 587700366 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_29\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230946   nanos: 756932497 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230946   nanos: 801789283 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230946   nanos: 755035161 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230946   nanos: 801789283 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230946   nanos: 798789739 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230946   nanos: 817791938 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230946   nanos: 843792438 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230946   nanos: 970790386 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230957   nanos: 210055351 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_84\" transform_id: \"TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230957   nanos: 213052272 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_83\" transform_id: \"TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-10\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230957   nanos: 220055341 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_85\" transform_id: \"TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729230957   nanos: 225052833 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_86\" transform_id: \"TFXIORead[eval]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\envs\\mlops-stroke\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\envs\\mlops-stroke\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231033   nanos: 370812654 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231033   nanos: 475819110 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231033   nanos: 391813993 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231033   nanos: 481815814 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231033   nanos: 455814599 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231033   nanos: 589442491 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231033   nanos: 694707632 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231033   nanos: 869759082 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231042   nanos: 640145063 } message: \"From C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow_transform\\\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nUse ref() instead.\" instruction_id: \"bundle_258\" transform_id: \"Analyze/CreateSavedModelForAnalyzerInputs[Phase0][tf_v2_only]/CreateSavedModel\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\deprecation.py:350\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231058   nanos: 485662937 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_450\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231058   nanos: 504662752 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_451\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231058   nanos: 551665306 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_453\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231058   nanos: 614226341 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_452\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " gender_xf (InputLayer)         [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " ever_married_xf (InputLayer)   [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " work_type_xf (InputLayer)      [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " Residence_type_xf (InputLayer)  [(None, 3)]         0           []                               \n",
      "                                                                                                  \n",
      " smoking_status_xf (InputLayer)  [(None, 5)]         0           []                               \n",
      "                                                                                                  \n",
      " age_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " hypertension_xf (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " heart_disease_xf (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " avg_glucose_level_xf (InputLay  [(None, 1)]         0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " bmi_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 24)           0           ['gender_xf[0][0]',              \n",
      "                                                                  'ever_married_xf[0][0]',        \n",
      "                                                                  'work_type_xf[0][0]',           \n",
      "                                                                  'Residence_type_xf[0][0]',      \n",
      "                                                                  'smoking_status_xf[0][0]',      \n",
      "                                                                  'age_xf[0][0]',                 \n",
      "                                                                  'hypertension_xf[0][0]',        \n",
      "                                                                  'heart_disease_xf[0][0]',       \n",
      "                                                                  'avg_glucose_level_xf[0][0]',   \n",
      "                                                                  'bmi_xf[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          6400        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           16448       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           1040        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            17          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,905\n",
      "Trainable params: 23,905\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 22s 4ms/step - loss: 0.1256 - binary_accuracy: 0.9566 - val_loss: 0.4715 - val_binary_accuracy: 0.9364\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 21s 4ms/step - loss: 0.0792 - binary_accuracy: 0.9682 - val_loss: 0.8606 - val_binary_accuracy: 0.9396\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 20s 4ms/step - loss: 0.0541 - binary_accuracy: 0.9780 - val_loss: 1.3031 - val_binary_accuracy: 0.9303\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 21s 4ms/step - loss: 0.0390 - binary_accuracy: 0.9840 - val_loss: 1.5486 - val_binary_accuracy: 0.9273\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 20s 4ms/step - loss: 0.0318 - binary_accuracy: 0.9867 - val_loss: 1.6603 - val_binary_accuracy: 0.9295\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 20s 4ms/step - loss: 0.0252 - binary_accuracy: 0.9893 - val_loss: 1.7734 - val_binary_accuracy: 0.9356\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 20s 4ms/step - loss: 0.0216 - binary_accuracy: 0.9902 - val_loss: 1.8608 - val_binary_accuracy: 0.9263\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 21s 4ms/step - loss: 0.0189 - binary_accuracy: 0.9915 - val_loss: 1.9028 - val_binary_accuracy: 0.9181\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 21s 4ms/step - loss: 0.0173 - binary_accuracy: 0.9926 - val_loss: 2.1016 - val_binary_accuracy: 0.9275\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 20s 4ms/step - loss: 0.0148 - binary_accuracy: 0.9935 - val_loss: 2.0335 - val_binary_accuracy: 0.9252\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output\\stroke-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output\\stroke-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000021A48574A30> and <keras.engine.input_layer.InputLayer object at 0x0000021A48A3D5E0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000021A48574A30> and <keras.engine.input_layer.InputLayer object at 0x0000021A48A3D5E0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000021A601CE520> and <keras.engine.input_layer.InputLayer object at 0x0000021A48E49EE0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000021A601CE520> and <keras.engine.input_layer.InputLayer object at 0x0000021A48E49EE0>).\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231356   nanos: 436959028 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231356   nanos: 452587842 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231356   nanos: 468214035 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231356   nanos: 510823249 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231356   nanos: 452587842 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231356   nanos: 495175361 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231356   nanos: 734597444 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231356   nanos: 751244544 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231373   nanos: 565230846 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000025280B438B0> and <keras.engine.input_layer.InputLayer object at 0x0000025292619AF0>).\" instruction_id: \"bundle_1153\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231373   nanos: 572230100 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000022B567DD8E0> and <keras.engine.input_layer.InputLayer object at 0x0000022B68E6E520>).\" instruction_id: \"bundle_1155\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231373   nanos: 601616382 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000026A3DE95FA0> and <keras.engine.input_layer.InputLayer object at 0x0000026A5DA639A0>).\" instruction_id: \"bundle_1152\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231373   nanos: 653200626 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001A7208599A0> and <keras.engine.input_layer.InputLayer object at 0x000001A720842C70>).\" instruction_id: \"bundle_1154\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231376   nanos: 413033485 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000022B6B41E730> and <keras.engine.input_layer.InputLayer object at 0x0000022B6B3FA400>).\" instruction_id: \"bundle_1155\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231376   nanos: 472852706 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000026A60026BB0> and <keras.engine.input_layer.InputLayer object at 0x0000026A60006880>).\" instruction_id: \"bundle_1152\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231376   nanos: 475853204 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000025295BDF2E0> and <keras.engine.input_layer.InputLayer object at 0x0000025295BB7E80>).\" instruction_id: \"bundle_1153\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231376   nanos: 572729349 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001A722E0D670> and <keras.engine.input_layer.InputLayer object at 0x000001A722DE8340>).\" instruction_id: \"bundle_1154\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231376   nanos: 864718198 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1155\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231376   nanos: 932218074 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1152\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231376   nanos: 992219209 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1153\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231377   nanos: 46670675 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1154\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231381   nanos: 11146068 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000022B709CCBB0> and <keras.engine.input_layer.InputLayer object at 0x0000022B709A6610>).\" instruction_id: \"bundle_1175\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231381   nanos: 11146068 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002529B195E20> and <keras.engine.input_layer.InputLayer object at 0x000002529B15F4F0>).\" instruction_id: \"bundle_1173\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231381   nanos: 55389881 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000026A655CAAC0> and <keras.engine.input_layer.InputLayer object at 0x0000026A655A0520>).\" instruction_id: \"bundle_1172\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231381   nanos: 84744691 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001A7283DCAC0> and <keras.engine.input_layer.InputLayer object at 0x000001A7283B6520>).\" instruction_id: \"bundle_1174\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231383   nanos: 852202892 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002529D58E9D0> and <keras.engine.input_layer.InputLayer object at 0x000002529B175F70>).\" instruction_id: \"bundle_1173\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231383   nanos: 875257492 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000022B72DCE490> and <keras.engine.input_layer.InputLayer object at 0x0000022B709AB430>).\" instruction_id: \"bundle_1175\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231383   nanos: 877256870 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001A72A7E33A0> and <keras.engine.input_layer.InputLayer object at 0x000001A7283BC250>).\" instruction_id: \"bundle_1174\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231383   nanos: 954516172 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000026A679CA550> and <keras.engine.input_layer.InputLayer object at 0x0000026A655A9220>).\" instruction_id: \"bundle_1172\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231386   nanos: 816301822 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002529F9C68E0> and <keras.engine.input_layer.InputLayer object at 0x000002529F99D6D0>).\" instruction_id: \"bundle_1185\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231386   nanos: 836302042 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000022B751F5DF0> and <keras.engine.input_layer.InputLayer object at 0x0000022B751CCBE0>).\" instruction_id: \"bundle_1187\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231386   nanos: 857301473 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000026A69E50670> and <keras.engine.input_layer.InputLayer object at 0x0000026A69E14460>).\" instruction_id: \"bundle_1184\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231386   nanos: 870216369 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001A72CC47D00> and <keras.engine.input_layer.InputLayer object at 0x000001A72CC1DAF0>).\" instruction_id: \"bundle_1186\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231390   nanos: 84643125 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000022B777433A0> and <keras.engine.input_layer.InputLayer object at 0x0000022B776F9F40>).\" instruction_id: \"bundle_1199\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231390   nanos: 87647676 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001A72F1473A0> and <keras.engine.input_layer.InputLayer object at 0x000001A72F120790>).\" instruction_id: \"bundle_1198\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231390   nanos: 118738889 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000026A6C2FCE80> and <keras.engine.input_layer.InputLayer object at 0x0000026A6C2D9AC0>).\" instruction_id: \"bundle_1196\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231390   nanos: 153561353 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000252A1F4C1C0> and <keras.engine.input_layer.InputLayer object at 0x00000252A1EE3640>).\" instruction_id: \"bundle_1197\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231392   nanos: 301271200 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000022B79CBF6A0> and <keras.engine.input_layer.InputLayer object at 0x0000022B79B1C9D0>).\" instruction_id: \"bundle_1199\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231392   nanos: 372223377 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001A7315706A0> and <keras.engine.input_layer.InputLayer object at 0x000001A72F137C70>).\" instruction_id: \"bundle_1198\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231392   nanos: 393139600 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000026A6E76E1C0> and <keras.engine.input_layer.InputLayer object at 0x0000026A6C2DF5B0>).\" instruction_id: \"bundle_1196\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729231392   nanos: 440011501 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000252A44884C0> and <keras.engine.input_layer.InputLayer object at 0x00000252A1EE3F40>).\" instruction_id: \"bundle_1197\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-stroke\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\envs\\mlops-stroke\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\envs\\mlops-stroke\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    }
   ],
   "source": [
    "components = init_components(\n",
    "    data_dir=DATA_ROOT,\n",
    "    transform_module=TRANSFORM_MODULE_FILE,\n",
    "    training_module=TRAINER_MODULE_FILE,\n",
    "    training_steps=5000,\n",
    "    eval_steps=1000,\n",
    "    serving_model_dir=serving_model_dir\n",
    ")\n",
    "\n",
    "pipeline = init_local_pipeline(components, pipeline_root)\n",
    "BeamDagRunner().run(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-stroke",
   "language": "python",
   "name": "mlops-stroke"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
